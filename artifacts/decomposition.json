{
  "DictionaryLearning": {
    "name": "sklearn.decomposition._dict_learning.DictionaryLearning",
    "common_name": "DictionaryLearning",
    "description": "Dictionary learning Finds a dictionary (a set of atoms) that can best be used to represent data using a sparse code.  Solves the optimization problem::      (U^*,V^*) = argmin 0.5 || X - U V ||_2^2 + alpha * || U ||_1                 (U,V)                 with || V_k ||_2 = 1 for all  0 <= k < n_components  Read more in the :ref:`User Guide <DictionaryLearning>`.",
    "sklearn_version": "0.24.0",
    "Hyperparams": [
      {
        "name": "n_components",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "n_components"
          ],
          "default": "n_components__None",
          "description": "Number of dictionary elements to extract."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "n_components__int",
            "init_args": {
              "semantic_types": [
                "n_components"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "n_components__None",
            "init_args": {
              "semantic_types": [
                "n_components"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "type": "Hyperparameter",
        "name": "alpha",
        "init_args": {
          "semantic_types": [
            "alpha"
          ],
          "_structural_type": "float",
          "default": 1,
          "description": "Sparsity controlling parameter."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "max_iter",
        "init_args": {
          "semantic_types": [
            "max_iter"
          ],
          "_structural_type": "int",
          "default": 1000,
          "description": "Maximum number of iterations to perform."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "tol",
        "init_args": {
          "semantic_types": [
            "tol"
          ],
          "_structural_type": "float",
          "default": 1e-08,
          "description": "Tolerance for numerical error."
        }
      },
      {
        "type": "Enumeration",
        "name": "fit_algorithm",
        "init_args": {
          "semantic_types": [
            "fit_algorithm"
          ],
          "values": [
            "lars",
            "cd"
          ],
          "_structural_type": "str",
          "default": "lars",
          "description": "* `'lars'`: uses the least angle regression method to solve the lasso    problem (`linear_model.lars_path`); * `'cd'`: uses the coordinate descent method to compute the   Lasso solution (`linear_model.Lasso`). Lars will be faster if   the estimated components are sparse.  .. versionadded:: 0.17    *cd* coordinate descent method to improve speed."
        }
      },
      {
        "type": "Enumeration",
        "name": "transform_algorithm",
        "init_args": {
          "semantic_types": [
            "transform_algorithm"
          ],
          "values": [
            "lasso_lars",
            "lasso_cd",
            "lars",
            "omp",
            "threshold"
          ],
          "_structural_type": "str",
          "default": "omp",
          "description": "Algorithm used to transform the data:  - `'lars'`: uses the least angle regression method   (`linear_model.lars_path`); - `'lasso_lars'`: uses Lars to compute the Lasso solution. - `'lasso_cd'`: uses the coordinate descent method to compute the   Lasso solution (`linear_model.Lasso`). `'lasso_lars'` will be faster   if the estimated components are sparse. - `'omp'`: uses orthogonal matching pursuit to estimate the sparse   solution. - `'threshold'`: squashes to zero all coefficients less than alpha from   the projection ``dictionary * X'``.  .. versionadded:: 0.17    *lasso_cd* coordinate descent method to improve speed."
        }
      },
      {
        "name": "transform_n_nonzero_coefs",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "transform_n_nonzero_coefs"
          ],
          "default": "transform_n_nonzero_coefs__None",
          "description": "Number of nonzero coefficients to target in each column of the solution. This is only used by `algorithm='lars'` and `algorithm='omp'` and is overridden by `alpha` in the `omp` case. If `None`, then `transform_n_nonzero_coefs=int(n_features / 10)`."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "transform_n_nonzero_coefs__int",
            "init_args": {
              "semantic_types": [
                "transform_n_nonzero_coefs"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "transform_n_nonzero_coefs__None",
            "init_args": {
              "semantic_types": [
                "transform_n_nonzero_coefs"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "name": "transform_alpha",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "transform_alpha"
          ],
          "default": "transform_alpha__None",
          "description": "If `algorithm='lasso_lars'` or `algorithm='lasso_cd'`, `alpha` is the penalty applied to the L1 norm. If `algorithm='threshold'`, `alpha` is the absolute value of the threshold below which coefficients will be squashed to zero. If `algorithm='omp'`, `alpha` is the tolerance parameter: the value of the reconstruction error targeted. In this case, it overrides `n_nonzero_coefs`. If `None`, default to 1.0"
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "transform_alpha__float",
            "init_args": {
              "semantic_types": [
                "transform_alpha"
              ],
              "_structural_type": "float"
            }
          },
          {
            "type": "Constant",
            "name": "transform_alpha__None",
            "init_args": {
              "semantic_types": [
                "transform_alpha"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "name": "n_jobs",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "n_jobs"
          ],
          "default": "n_jobs__None",
          "description": "Number of parallel jobs to run. ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. ``-1`` means using all processors. See :term:`Glossary <n_jobs>` for more details."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "n_jobs__int",
            "init_args": {
              "semantic_types": [
                "n_jobs"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "n_jobs__None",
            "init_args": {
              "semantic_types": [
                "n_jobs"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "name": "code_init",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "code_init"
          ],
          "default": "code_init__None",
          "description": "Initial value for the code, for warm restart."
        },
        "hyperparams": [
          {
            "name": "code_init__ndarray",
            "type": "Hyperparameter",
            "init_args": {
              "_structural_type": "ndarray",
              "semantic_types": [
                "code_init"
              ]
            }
          },
          {
            "type": "Constant",
            "name": "code_init__None",
            "init_args": {
              "semantic_types": [
                "code_init"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "name": "dict_init",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "dict_init"
          ],
          "default": "dict_init__None",
          "description": "Initial values for the dictionary, for warm restart."
        },
        "hyperparams": [
          {
            "name": "dict_init__ndarray",
            "type": "Hyperparameter",
            "init_args": {
              "_structural_type": "ndarray",
              "semantic_types": [
                "dict_init"
              ]
            }
          },
          {
            "type": "Constant",
            "name": "dict_init__None",
            "init_args": {
              "semantic_types": [
                "dict_init"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "type": "Hyperparameter",
        "name": "verbose",
        "init_args": {
          "semantic_types": [
            "verbose"
          ],
          "_structural_type": "bool",
          "default": "False",
          "description": "To control the verbosity of the procedure."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "split_sign",
        "init_args": {
          "semantic_types": [
            "split_sign"
          ],
          "_structural_type": "bool",
          "default": "False",
          "description": "Whether to split the sparse feature vector into the concatenation of its negative part and its positive part. This can improve the performance of downstream classifiers."
        }
      },
      {
        "name": "random_state",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "random_state"
          ],
          "default": "random_state__None",
          "description": "Used for initializing the dictionary when ``dict_init`` is not specified, randomly shuffling the data when ``shuffle`` is set to ``True``, and updating the dictionary. Pass an int for reproducible results across multiple function calls. See :term:`Glossary <random_state>`."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "random_state__int",
            "init_args": {
              "semantic_types": [
                "random_state"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "random_state__None",
            "init_args": {
              "semantic_types": [
                "random_state"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "type": "Hyperparameter",
        "name": "positive_code",
        "init_args": {
          "semantic_types": [
            "positive_code"
          ],
          "_structural_type": "bool",
          "default": "False",
          "description": "Whether to enforce positivity when finding the code.  .. versionadded:: 0.20"
        }
      },
      {
        "type": "Hyperparameter",
        "name": "positive_dict",
        "init_args": {
          "semantic_types": [
            "positive_dict"
          ],
          "_structural_type": "bool",
          "default": "False",
          "description": "Whether to enforce positivity when finding the dictionary  .. versionadded:: 0.20"
        }
      },
      {
        "type": "Hyperparameter",
        "name": "transform_max_iter",
        "init_args": {
          "semantic_types": [
            "transform_max_iter"
          ],
          "_structural_type": "int",
          "default": 1000,
          "description": "Maximum number of iterations to perform if `algorithm='lasso_cd'` or `'lasso_lars'`.  .. versionadded:: 0.22"
        }
      }
    ],
    "Params": [
      {
        "name": "components_",
        "type": "ndarray of shape (n_components, n_features)",
        "description": "dictionary atoms extracted from the data"
      },
      {
        "name": "error_",
        "type": "array",
        "description": "vector of errors at each iteration"
      },
      {
        "name": "n_iter_",
        "type": "int",
        "description": "Number of iterations run."
      }
    ]
  },
  "FactorAnalysis": {
    "name": "sklearn.decomposition._factor_analysis.FactorAnalysis",
    "common_name": "FactorAnalysis",
    "description": "Factor Analysis (FA). A simple linear generative model with Gaussian latent variables.  The observations are assumed to be caused by a linear transformation of lower dimensional latent factors and added Gaussian noise. Without loss of generality the factors are distributed according to a Gaussian with zero mean and unit covariance. The noise is also zero mean and has an arbitrary diagonal covariance matrix.  If we would restrict the model further, by assuming that the Gaussian noise is even isotropic (all diagonal entries are the same) we would obtain :class:`PPCA`.  FactorAnalysis performs a maximum likelihood estimate of the so-called `loading` matrix, the transformation of the latent variables to the observed ones, using SVD based approach.  Read more in the :ref:`User Guide <FA>`.  .. versionadded:: 0.13",
    "sklearn_version": "0.24.0",
    "Hyperparams": [
      {
        "name": "n_components",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "n_components"
          ],
          "default": "n_components__None",
          "description": "Dimensionality of latent space, the number of components of ``X`` that are obtained after ``transform``. If None, n_components is set to the number of features."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "n_components__int",
            "init_args": {
              "semantic_types": [
                "n_components"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "n_components__None",
            "init_args": {
              "semantic_types": [
                "n_components"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "type": "Hyperparameter",
        "name": "tol",
        "init_args": {
          "semantic_types": [
            "tol"
          ],
          "_structural_type": "float",
          "default": 0.01,
          "description": "Stopping tolerance for log-likelihood increase."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "copy",
        "init_args": {
          "semantic_types": [
            "copy"
          ],
          "_structural_type": "bool",
          "default": "True",
          "description": "Whether to make a copy of X. If ``False``, the input X gets overwritten during fitting."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "max_iter",
        "init_args": {
          "semantic_types": [
            "max_iter"
          ],
          "_structural_type": "int",
          "default": 1000,
          "description": "Maximum number of iterations."
        }
      },
      {
        "name": "noise_variance_init",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "noise_variance_init"
          ],
          "default": "noise_variance_init__None",
          "description": "The initial guess of the noise variance for each feature. If None, it defaults to np.ones(n_features)."
        },
        "hyperparams": [
          {
            "name": "noise_variance_init__ndarray",
            "type": "Hyperparameter",
            "init_args": {
              "_structural_type": "ndarray",
              "semantic_types": [
                "noise_variance_init"
              ]
            }
          },
          {
            "type": "Constant",
            "name": "noise_variance_init__None",
            "init_args": {
              "semantic_types": [
                "noise_variance_init"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "type": "Enumeration",
        "name": "svd_method",
        "init_args": {
          "semantic_types": [
            "svd_method"
          ],
          "values": [
            "lapack",
            "randomized"
          ],
          "_structural_type": "str",
          "default": "randomized",
          "description": "Which SVD method to use. If 'lapack' use standard SVD from scipy.linalg, if 'randomized' use fast ``randomized_svd`` function. Defaults to 'randomized'. For most applications 'randomized' will be sufficiently precise while providing significant speed gains. Accuracy can also be improved by setting higher values for `iterated_power`. If this is not sufficient, for maximum precision you should choose 'lapack'."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "iterated_power",
        "init_args": {
          "semantic_types": [
            "iterated_power"
          ],
          "_structural_type": "int",
          "default": 3,
          "description": "Number of iterations for the power method. 3 by default. Only used if ``svd_method`` equals 'randomized'."
        }
      },
      {
        "type": "Enumeration",
        "name": "rotation",
        "init_args": {
          "semantic_types": [
            "rotation"
          ],
          "values": [
            "varimax",
            "quartimax"
          ],
          "_structural_type": "str",
          "default": "None",
          "description": "If not None, apply the indicated rotation. Currently, varimax and quartimax are implemented. See `\"The varimax criterion for analytic rotation in factor analysis\" <https://link.springer.com/article/10.1007%2FBF02289233>`_ H. F. Kaiser, 1958.  .. versionadded:: 0.24"
        }
      },
      {
        "name": "random_state",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "random_state"
          ],
          "default": "random_state__int",
          "description": "Only used when ``svd_method`` equals 'randomized'. Pass an int for reproducible results across multiple function calls. See :term:`Glossary <random_state>`."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "random_state__int",
            "init_args": {
              "semantic_types": [
                "random_state"
              ],
              "_structural_type": "int",
              "default": 0
            }
          },
          {
            "type": "Constant",
            "name": "random_state__None",
            "init_args": {
              "semantic_types": [
                "random_state"
              ],
              "_structural_type": "None"
            }
          }
        ]
      }
    ],
    "Params": [
      {
        "name": "components_",
        "type": "ndarray of shape (n_components, n_features)",
        "description": "Components with maximum variance."
      },
      {
        "name": "loglike_",
        "type": "list of shape (n_iterations,)",
        "description": "The log likelihood at each iteration."
      },
      {
        "name": "noise_variance_",
        "type": "ndarray of shape (n_features,)",
        "description": "The estimated noise variance for each feature."
      },
      {
        "name": "n_iter_",
        "type": "int",
        "description": "Number of iterations run."
      },
      {
        "name": "mean_",
        "type": "ndarray of shape (n_features,)",
        "description": "Per-feature empirical mean, estimated from the training set."
      }
    ]
  },
  "FastICA": {
    "name": "sklearn.decomposition._fastica.FastICA",
    "common_name": "FastICA",
    "description": "FastICA: a fast algorithm for Independent Component Analysis. Read more in the :ref:`User Guide <ICA>`.",
    "sklearn_version": "0.24.0",
    "Hyperparams": [
      {
        "name": "n_components",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "n_components"
          ],
          "default": "n_components__None",
          "description": "Number of components to use. If None is passed, all are used."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "n_components__int",
            "init_args": {
              "semantic_types": [
                "n_components"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "n_components__None",
            "init_args": {
              "semantic_types": [
                "n_components"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "type": "Enumeration",
        "name": "algorithm",
        "init_args": {
          "semantic_types": [
            "algorithm"
          ],
          "values": [
            "parallel",
            "deflation"
          ],
          "_structural_type": "str",
          "default": "parallel",
          "description": "Apply parallel or deflational algorithm for FastICA."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "whiten",
        "init_args": {
          "semantic_types": [
            "whiten"
          ],
          "_structural_type": "bool",
          "default": "True",
          "description": "If whiten is false, the data is already considered to be whitened, and no whitening is performed."
        }
      },
      {
        "name": "fun",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "fun"
          ],
          "default": "fun__str",
          "description": "The functional form of the G function used in the approximation to neg-entropy. Could be either 'logcosh', 'exp', or 'cube'. You can also provide your own function. It should return a tuple containing the value of the function, and of its derivative, in the point. Example::      def my_g(x):         return x ** 3, (3 * x ** 2).mean(axis=-1)"
        },
        "hyperparams": [
          {
            "type": "Enumeration",
            "name": "fun__str",
            "init_args": {
              "semantic_types": [
                "fun"
              ],
              "values": [
                "logcosh",
                "exp",
                "cube"
              ],
              "_structural_type": "str",
              "default": "logcosh"
            }
          },
          {
            "type": "Hyperparameter",
            "name": "fun__Callable",
            "init_args": {
              "semantic_types": [
                "fun"
              ],
              "_structural_type": "Callable"
            }
          }
        ]
      },
      {
        "name": "fun_args",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "fun_args"
          ],
          "default": "fun_args__None",
          "description": "Arguments to send to the functional form. If empty and if fun='logcosh', fun_args will take value {'alpha' : 1.0}."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "fun_args__dict",
            "init_args": {
              "semantic_types": [
                "fun_args"
              ],
              "_structural_type": "dict"
            }
          },
          {
            "type": "Constant",
            "name": "fun_args__None",
            "init_args": {
              "semantic_types": [
                "fun_args"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "type": "Hyperparameter",
        "name": "max_iter",
        "init_args": {
          "semantic_types": [
            "max_iter"
          ],
          "_structural_type": "int",
          "default": 200,
          "description": "Maximum number of iterations during fit."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "tol",
        "init_args": {
          "semantic_types": [
            "tol"
          ],
          "_structural_type": "float",
          "default": 0.0001,
          "description": "Tolerance on update at each iteration."
        }
      },
      {
        "name": "w_init",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "w_init"
          ],
          "default": "w_init__None",
          "description": "The mixing matrix to be used to initialize the algorithm."
        },
        "hyperparams": [
          {
            "name": "w_init__ndarray",
            "type": "Hyperparameter",
            "init_args": {
              "_structural_type": "ndarray",
              "semantic_types": [
                "w_init"
              ]
            }
          },
          {
            "type": "Constant",
            "name": "w_init__None",
            "init_args": {
              "semantic_types": [
                "w_init"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "name": "random_state",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "random_state"
          ],
          "default": "random_state__None",
          "description": "Used to initialize ``w_init`` when not specified, with a normal distribution. Pass an int, for reproducible results across multiple function calls. See :term:`Glossary <random_state>`."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "random_state__int",
            "init_args": {
              "semantic_types": [
                "random_state"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "random_state__None",
            "init_args": {
              "semantic_types": [
                "random_state"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      }
    ],
    "Params": [
      {
        "name": "components_",
        "type": "ndarray of shape (n_components, n_features)",
        "description": "The linear operator to apply to the data to get the independent sources. This is equal to the unmixing matrix when ``whiten`` is False, and equal to ``np.dot(unmixing_matrix, self.whitening_)`` when ``whiten`` is True."
      },
      {
        "name": "mixing_",
        "type": "ndarray of shape (n_features, n_components)",
        "description": "The pseudo-inverse of ``components_``. It is the linear operator that maps independent sources to the data."
      },
      {
        "name": "mean_",
        "type": "ndarray of shape(n_features,)",
        "description": "The mean over features. Only set if `self.whiten` is True."
      },
      {
        "name": "n_iter_",
        "type": "int",
        "description": "If the algorithm is \"deflation\", n_iter is the maximum number of iterations run across all components. Else they are just the number of iterations taken to converge."
      },
      {
        "name": "whitening_",
        "type": "ndarray of shape (n_components, n_features)",
        "description": "Only set if whiten is 'True'. This is the pre-whitening matrix that projects data onto the first `n_components` principal components."
      }
    ]
  },
  "IncrementalPCA": {
    "name": "sklearn.decomposition._incremental_pca.IncrementalPCA",
    "common_name": "IncrementalPCA",
    "description": "Incremental principal components analysis (IPCA). Linear dimensionality reduction using Singular Value Decomposition of the data, keeping only the most significant singular vectors to project the data to a lower dimensional space. The input data is centered but not scaled for each feature before applying the SVD.  Depending on the size of the input data, this algorithm can be much more memory efficient than a PCA, and allows sparse input.  This algorithm has constant memory complexity, on the order of ``batch_size * n_features``, enabling use of np.memmap files without loading the entire file into memory. For sparse matrices, the input is converted to dense in batches (in order to be able to subtract the mean) which avoids storing the entire dense matrix at any one time.  The computational overhead of each SVD is ``O(batch_size * n_features ** 2)``, but only 2 * batch_size samples remain in memory at a time. There will be ``n_samples / batch_size`` SVD computations to get the principal components, versus 1 large SVD of complexity ``O(n_samples * n_features ** 2)`` for PCA.  Read more in the :ref:`User Guide <IncrementalPCA>`.  .. versionadded:: 0.16",
    "sklearn_version": "0.24.0",
    "Hyperparams": [
      {
        "name": "n_components",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "n_components"
          ],
          "default": "n_components__None",
          "description": "Number of components to keep. If ``n_components`` is ``None``, then ``n_components`` is set to ``min(n_samples, n_features)``."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "n_components__int",
            "init_args": {
              "semantic_types": [
                "n_components"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "n_components__None",
            "init_args": {
              "semantic_types": [
                "n_components"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "type": "Hyperparameter",
        "name": "whiten",
        "init_args": {
          "semantic_types": [
            "whiten"
          ],
          "_structural_type": "bool",
          "default": "False",
          "description": "When True (False by default) the ``components_`` vectors are divided by ``n_samples`` times ``components_`` to ensure uncorrelated outputs with unit component-wise variances.  Whitening will remove some information from the transformed signal (the relative variance scales of the components) but can sometimes improve the predictive accuracy of the downstream estimators by making data respect some hard-wired assumptions."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "copy",
        "init_args": {
          "semantic_types": [
            "copy"
          ],
          "_structural_type": "bool",
          "default": "True",
          "description": "If False, X will be overwritten. ``copy=False`` can be used to save memory but is unsafe for general use."
        }
      },
      {
        "name": "batch_size",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "batch_size"
          ],
          "default": "batch_size__None",
          "description": "The number of samples to use for each batch. Only used when calling ``fit``. If ``batch_size`` is ``None``, then ``batch_size`` is inferred from the data and set to ``5 * n_features``, to provide a balance between approximation accuracy and memory consumption."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "batch_size__int",
            "init_args": {
              "semantic_types": [
                "batch_size"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "batch_size__None",
            "init_args": {
              "semantic_types": [
                "batch_size"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      }
    ],
    "Params": [
      {
        "name": "components_",
        "type": "ndarray of shape (n_components, n_features)",
        "description": "Components with maximum variance."
      },
      {
        "name": "explained_variance_",
        "type": "ndarray of shape (n_components,)",
        "description": "Variance explained by each of the selected components."
      },
      {
        "name": "explained_variance_ratio_",
        "type": "ndarray of shape (n_components,)",
        "description": "Percentage of variance explained by each of the selected components. If all components are stored, the sum of explained variances is equal to 1.0."
      },
      {
        "name": "singular_values_",
        "type": "ndarray of shape (n_components,)",
        "description": "The singular values corresponding to each of the selected components. The singular values are equal to the 2-norms of the ``n_components`` variables in the lower-dimensional space."
      },
      {
        "name": "mean_",
        "type": "ndarray of shape (n_features,)",
        "description": "Per-feature empirical mean, aggregate over calls to ``partial_fit``."
      },
      {
        "name": "var_",
        "type": "ndarray of shape (n_features,)",
        "description": "Per-feature empirical variance, aggregate over calls to ``partial_fit``."
      },
      {
        "name": "noise_variance_",
        "type": "float",
        "description": "The estimated noise covariance following the Probabilistic PCA model from Tipping and Bishop 1999. See \"Pattern Recognition and Machine Learning\" by C. Bishop, 12.2.1 p. 574 or http://www.miketipping.com/papers/met-mppca.pdf."
      },
      {
        "name": "n_components_",
        "type": "int",
        "description": "The estimated number of components. Relevant when ``n_components=None``."
      },
      {
        "name": "n_samples_seen_",
        "type": "int",
        "description": "The number of samples processed by the estimator. Will be reset on new calls to fit, but increments across ``partial_fit`` calls."
      },
      {
        "name": "batch_size_",
        "type": "int",
        "description": "Inferred batch size from ``batch_size``."
      }
    ]
  },
  "KernelPCA": {
    "name": "sklearn.decomposition._kernel_pca.KernelPCA",
    "common_name": "KernelPCA",
    "description": "Kernel Principal component analysis (KPCA). Non-linear dimensionality reduction through the use of kernels (see :ref:`metrics`).  Read more in the :ref:`User Guide <kernel_PCA>`.",
    "sklearn_version": "0.24.0",
    "Hyperparams": [
      {
        "type": "Constant",
        "name": "n_components",
        "init_args": {
          "semantic_types": [
            "n_components"
          ],
          "_structural_type": "None",
          "default": "None",
          "description": "Number of components. If None, all non-zero components are kept."
        }
      },
      {
        "type": "Enumeration",
        "name": "kernel",
        "init_args": {
          "semantic_types": [
            "kernel"
          ],
          "values": [
            "linear",
            "poly",
            "rbf",
            "sigmoid",
            "cosine",
            "precomputed"
          ],
          "_structural_type": "str",
          "default": "linear",
          "description": "Kernel used for PCA."
        }
      },
      {
        "name": "gamma",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "gamma"
          ],
          "default": "gamma__None",
          "description": "Kernel coefficient for rbf, poly and sigmoid kernels. Ignored by other kernels. If ``gamma`` is ``None``, then it is set to ``1/n_features``."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "gamma__float",
            "init_args": {
              "semantic_types": [
                "gamma"
              ],
              "_structural_type": "float"
            }
          },
          {
            "type": "Constant",
            "name": "gamma__None",
            "init_args": {
              "semantic_types": [
                "gamma"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "type": "Hyperparameter",
        "name": "degree",
        "init_args": {
          "semantic_types": [
            "degree"
          ],
          "_structural_type": "int",
          "default": 3,
          "description": "Degree for poly kernels. Ignored by other kernels."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "coef0",
        "init_args": {
          "semantic_types": [
            "coef0"
          ],
          "_structural_type": "float",
          "default": 1,
          "description": "Independent term in poly and sigmoid kernels. Ignored by other kernels."
        }
      },
      {
        "name": "kernel_params",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "kernel_params"
          ],
          "default": "kernel_params__None",
          "description": "Parameters (keyword arguments) and values for kernel passed as callable object. Ignored by other kernels."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "kernel_params__dict",
            "init_args": {
              "semantic_types": [
                "kernel_params"
              ],
              "_structural_type": "dict"
            }
          },
          {
            "type": "Constant",
            "name": "kernel_params__None",
            "init_args": {
              "semantic_types": [
                "kernel_params"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "type": "Hyperparameter",
        "name": "alpha",
        "init_args": {
          "semantic_types": [
            "alpha"
          ],
          "_structural_type": "float",
          "default": 1.0,
          "description": "Hyperparameter of the ridge regression that learns the inverse transform (when fit_inverse_transform=True)."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "fit_inverse_transform",
        "init_args": {
          "semantic_types": [
            "fit_inverse_transform"
          ],
          "_structural_type": "bool",
          "default": "False",
          "description": "Learn the inverse transform for non-precomputed kernels. (i.e. learn to find the pre-image of a point)"
        }
      },
      {
        "type": "Enumeration",
        "name": "eigen_solver",
        "init_args": {
          "semantic_types": [
            "eigen_solver"
          ],
          "values": [
            "auto",
            "dense",
            "arpack"
          ],
          "_structural_type": "str",
          "default": "auto",
          "description": "Select eigensolver to use. If n_components is much less than the number of training samples, arpack may be more efficient than the dense eigensolver."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "tol",
        "init_args": {
          "semantic_types": [
            "tol"
          ],
          "_structural_type": "float",
          "default": 0,
          "description": "Convergence tolerance for arpack. If 0, optimal value will be chosen by arpack."
        }
      },
      {
        "type": "Constant",
        "name": "max_iter",
        "init_args": {
          "semantic_types": [
            "max_iter"
          ],
          "_structural_type": "None",
          "default": "None",
          "description": "Maximum number of iterations for arpack. If None, optimal value will be chosen by arpack."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "remove_zero_eig",
        "init_args": {
          "semantic_types": [
            "remove_zero_eig"
          ],
          "_structural_type": "bool",
          "default": "False",
          "description": "If True, then all components with zero eigenvalues are removed, so that the number of components in the output may be < n_components (and sometimes even zero due to numerical instability). When n_components is None, this parameter is ignored and components with zero eigenvalues are removed regardless."
        }
      },
      {
        "name": "random_state",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "random_state"
          ],
          "default": "random_state__None",
          "description": "Used when ``eigen_solver`` == 'arpack'. Pass an int for reproducible results across multiple function calls. See :term:`Glossary <random_state>`.  .. versionadded:: 0.18"
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "random_state__int",
            "init_args": {
              "semantic_types": [
                "random_state"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "random_state__None",
            "init_args": {
              "semantic_types": [
                "random_state"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "type": "Hyperparameter",
        "name": "copy_X",
        "init_args": {
          "semantic_types": [
            "copy_X"
          ],
          "_structural_type": "bool",
          "default": "True",
          "description": "If True, input X is copied and stored by the model in the `X_fit_` attribute. If no further changes will be done to X, setting `copy_X=False` saves memory by storing a reference.  .. versionadded:: 0.18"
        }
      },
      {
        "name": "n_jobs",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "n_jobs"
          ],
          "default": "n_jobs__None",
          "description": "The number of parallel jobs to run. ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. ``-1`` means using all processors. See :term:`Glossary <n_jobs>` for more details.  .. versionadded:: 0.18"
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "n_jobs__int",
            "init_args": {
              "semantic_types": [
                "n_jobs"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "n_jobs__None",
            "init_args": {
              "semantic_types": [
                "n_jobs"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      }
    ],
    "Params": [
      {
        "name": "lambdas_",
        "type": "ndarray of shape (n_components,)",
        "description": "Eigenvalues of the centered kernel matrix in decreasing order. If `n_components` and `remove_zero_eig` are not set, then all values are stored."
      },
      {
        "name": "alphas_",
        "type": "ndarray of shape (n_samples, n_components)",
        "description": "Eigenvectors of the centered kernel matrix. If `n_components` and `remove_zero_eig` are not set, then all components are stored."
      },
      {
        "name": "dual_coef_",
        "type": "ndarray of shape (n_samples, n_features)",
        "description": "Inverse transform matrix. Only available when ``fit_inverse_transform`` is True."
      },
      {
        "name": "X_transformed_fit_",
        "type": "ndarray of shape (n_samples, n_components)",
        "description": "Projection of the fitted data on the kernel principal components. Only available when ``fit_inverse_transform`` is True."
      },
      {
        "name": "X_fit_",
        "type": "ndarray of shape (n_samples, n_features)",
        "description": "The data used to fit the model. If `copy_X=False`, then `X_fit_` is a reference. This attribute is used for the calls to transform."
      }
    ]
  },
  "LatentDirichletAllocation": {
    "name": "sklearn.decomposition._lda.LatentDirichletAllocation",
    "common_name": "LatentDirichletAllocation",
    "description": "Latent Dirichlet Allocation with online variational Bayes algorithm .. versionadded:: 0.17  Read more in the :ref:`User Guide <LatentDirichletAllocation>`.",
    "sklearn_version": "0.24.0",
    "Hyperparams": [
      {
        "type": "Hyperparameter",
        "name": "n_components",
        "init_args": {
          "semantic_types": [
            "n_components"
          ],
          "_structural_type": "int",
          "default": 10,
          "description": "Number of topics.  .. versionchanged:: 0.19     ``n_topics`` was renamed to ``n_components``"
        }
      },
      {
        "name": "doc_topic_prior",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "doc_topic_prior"
          ],
          "default": "doc_topic_prior__None",
          "description": "Prior of document topic distribution `theta`. If the value is None, defaults to `1 / n_components`. In [1]_, this is called `alpha`."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "doc_topic_prior__float",
            "init_args": {
              "semantic_types": [
                "doc_topic_prior"
              ],
              "_structural_type": "float"
            }
          },
          {
            "type": "Constant",
            "name": "doc_topic_prior__None",
            "init_args": {
              "semantic_types": [
                "doc_topic_prior"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "name": "topic_word_prior",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "topic_word_prior"
          ],
          "default": "topic_word_prior__None",
          "description": "Prior of topic word distribution `beta`. If the value is None, defaults to `1 / n_components`. In [1]_, this is called `eta`."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "topic_word_prior__float",
            "init_args": {
              "semantic_types": [
                "topic_word_prior"
              ],
              "_structural_type": "float"
            }
          },
          {
            "type": "Constant",
            "name": "topic_word_prior__None",
            "init_args": {
              "semantic_types": [
                "topic_word_prior"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "type": "Enumeration",
        "name": "learning_method",
        "init_args": {
          "semantic_types": [
            "learning_method"
          ],
          "values": [
            "batch",
            "online"
          ],
          "_structural_type": "str",
          "default": "batch",
          "description": "Method used to update `_component`. Only used in :meth:`fit` method. In general, if the data size is large, the online update will be much faster than the batch update.  Valid options::      'batch': Batch variational Bayes method. Use all training data in         each EM update.         Old `components_` will be overwritten in each iteration.     'online': Online variational Bayes method. In each EM update, use         mini-batch of training data to update the ``components_``         variable incrementally. The learning rate is controlled by the         ``learning_decay`` and the ``learning_offset`` parameters.  .. versionchanged:: 0.20     The default learning method is now ``\"batch\"``."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "learning_decay",
        "init_args": {
          "semantic_types": [
            "learning_decay"
          ],
          "_structural_type": "float",
          "default": 0.7,
          "description": "It is a parameter that control learning rate in the online learning method. The value should be set between (0.5, 1.0] to guarantee asymptotic convergence. When the value is 0.0 and batch_size is ``n_samples``, the update method is same as batch learning. In the literature, this is called kappa."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "learning_offset",
        "init_args": {
          "semantic_types": [
            "learning_offset"
          ],
          "_structural_type": "float",
          "default": 10.0,
          "description": "A (positive) parameter that downweights early iterations in online learning.  It should be greater than 1.0. In the literature, this is called tau_0."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "max_iter",
        "init_args": {
          "semantic_types": [
            "max_iter"
          ],
          "_structural_type": "int",
          "default": 10,
          "description": "The maximum number of iterations."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "batch_size",
        "init_args": {
          "semantic_types": [
            "batch_size"
          ],
          "_structural_type": "int",
          "default": 128,
          "description": "Number of documents to use in each EM iteration. Only used in online learning."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "evaluate_every",
        "init_args": {
          "semantic_types": [
            "evaluate_every"
          ],
          "_structural_type": "int",
          "default": -1,
          "description": "How often to evaluate perplexity. Only used in `fit` method. set it to 0 or negative number to not evaluate perplexity in training at all. Evaluating perplexity can help you check convergence in training process, but it will also increase total training time. Evaluating perplexity in every iteration might increase training time up to two-fold."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "total_samples",
        "init_args": {
          "semantic_types": [
            "total_samples"
          ],
          "_structural_type": "int",
          "default": 1000000.0,
          "description": "Total number of documents. Only used in the :meth:`partial_fit` method."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "perp_tol",
        "init_args": {
          "semantic_types": [
            "perp_tol"
          ],
          "_structural_type": "float",
          "default": 0.1,
          "description": "Perplexity tolerance in batch learning. Only used when ``evaluate_every`` is greater than 0."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "mean_change_tol",
        "init_args": {
          "semantic_types": [
            "mean_change_tol"
          ],
          "_structural_type": "float",
          "default": 0.001,
          "description": "Stopping tolerance for updating document topic distribution in E-step."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "max_doc_update_iter",
        "init_args": {
          "semantic_types": [
            "max_doc_update_iter"
          ],
          "_structural_type": "int",
          "default": 100,
          "description": "Max number of iterations for updating document topic distribution in the E-step."
        }
      },
      {
        "name": "n_jobs",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "n_jobs"
          ],
          "default": "n_jobs__None",
          "description": "The number of jobs to use in the E-step. ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. ``-1`` means using all processors. See :term:`Glossary <n_jobs>` for more details."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "n_jobs__int",
            "init_args": {
              "semantic_types": [
                "n_jobs"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "n_jobs__None",
            "init_args": {
              "semantic_types": [
                "n_jobs"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "type": "Hyperparameter",
        "name": "verbose",
        "init_args": {
          "semantic_types": [
            "verbose"
          ],
          "_structural_type": "int",
          "default": 0,
          "description": "Verbosity level."
        }
      },
      {
        "name": "random_state",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "random_state"
          ],
          "default": "random_state__None",
          "description": "Pass an int for reproducible results across multiple function calls. See :term:`Glossary <random_state>`."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "random_state__int",
            "init_args": {
              "semantic_types": [
                "random_state"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "random_state__None",
            "init_args": {
              "semantic_types": [
                "random_state"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      }
    ],
    "Params": [
      {
        "name": "components_",
        "type": "ndarray of shape (n_components, n_features)",
        "description": "Variational parameters for topic word distribution. Since the complete conditional for topic word distribution is a Dirichlet, ``components_[i, j]`` can be viewed as pseudocount that represents the number of times word `j` was assigned to topic `i`. It can also be viewed as distribution over the words for each topic after normalization: ``model.components_ / model.components_.sum(axis=1)[:, np.newaxis]``."
      },
      {
        "name": "exp_dirichlet_component_",
        "type": "ndarray of shape (n_components, n_features)",
        "description": "Exponential value of expectation of log topic word distribution. In the literature, this is `exp(E[log(beta)])`."
      },
      {
        "name": "n_batch_iter_",
        "type": "int",
        "description": "Number of iterations of the EM step."
      },
      {
        "name": "n_iter_",
        "type": "int",
        "description": "Number of passes over the dataset."
      },
      {
        "name": "bound_",
        "type": "float",
        "description": "Final perplexity score on training set."
      },
      {
        "name": "doc_topic_prior_",
        "type": "float",
        "description": "Prior of document topic distribution `theta`. If the value is None, it is `1 / n_components`."
      },
      {
        "name": "random_state_",
        "type": "RandomState instance",
        "description": "RandomState instance that is generated either from a seed, the random number generator or by `np.random`."
      },
      {
        "name": "topic_word_prior_",
        "type": "float",
        "description": "Prior of topic word distribution `beta`. If the value is None, it is `1 / n_components`."
      }
    ]
  },
  "MiniBatchDictionaryLearning": {
    "name": "sklearn.decomposition._dict_learning.MiniBatchDictionaryLearning",
    "common_name": "MiniBatchDictionaryLearning",
    "description": "Mini-batch dictionary learning Finds a dictionary (a set of atoms) that can best be used to represent data using a sparse code.  Solves the optimization problem::     (U^*,V^*) = argmin 0.5 || X - U V ||_2^2 + alpha * || U ||_1                 (U,V)                 with || V_k ||_2 = 1 for all  0 <= k < n_components  Read more in the :ref:`User Guide <DictionaryLearning>`.",
    "sklearn_version": "0.24.0",
    "Hyperparams": [
      {
        "type": "Constant",
        "name": "n_components",
        "init_args": {
          "semantic_types": [
            "n_components"
          ],
          "_structural_type": "None",
          "default": "None",
          "description": "Number of dictionary elements to extract."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "alpha",
        "init_args": {
          "semantic_types": [
            "alpha"
          ],
          "_structural_type": "float",
          "default": 1,
          "description": "Sparsity controlling parameter."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "n_iter",
        "init_args": {
          "semantic_types": [
            "n_iter"
          ],
          "_structural_type": "int",
          "default": 1000,
          "description": "Total number of iterations to perform."
        }
      },
      {
        "type": "Enumeration",
        "name": "fit_algorithm",
        "init_args": {
          "semantic_types": [
            "fit_algorithm"
          ],
          "values": [
            "lars",
            "cd"
          ],
          "_structural_type": "str",
          "default": "lars",
          "description": "The algorithm used:  - `'lars'`: uses the least angle regression method to solve the lasso   problem (`linear_model.lars_path`) - `'cd'`: uses the coordinate descent method to compute the   Lasso solution (`linear_model.Lasso`). Lars will be faster if   the estimated components are sparse."
        }
      },
      {
        "name": "n_jobs",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "n_jobs"
          ],
          "default": "n_jobs__None",
          "description": "Number of parallel jobs to run. ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. ``-1`` means using all processors. See :term:`Glossary <n_jobs>` for more details."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "n_jobs__int",
            "init_args": {
              "semantic_types": [
                "n_jobs"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "n_jobs__None",
            "init_args": {
              "semantic_types": [
                "n_jobs"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "type": "Hyperparameter",
        "name": "batch_size",
        "init_args": {
          "semantic_types": [
            "batch_size"
          ],
          "_structural_type": "int",
          "default": 3,
          "description": "Number of samples in each mini-batch."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "shuffle",
        "init_args": {
          "semantic_types": [
            "shuffle"
          ],
          "_structural_type": "bool",
          "default": "True",
          "description": "Whether to shuffle the samples before forming batches."
        }
      },
      {
        "name": "dict_init",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "dict_init"
          ],
          "default": "dict_init__None",
          "description": "initial value of the dictionary for warm restart scenarios"
        },
        "hyperparams": [
          {
            "name": "dict_init__ndarray",
            "type": "Hyperparameter",
            "init_args": {
              "_structural_type": "ndarray",
              "semantic_types": [
                "dict_init"
              ]
            }
          },
          {
            "type": "Constant",
            "name": "dict_init__None",
            "init_args": {
              "semantic_types": [
                "dict_init"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "type": "Enumeration",
        "name": "transform_algorithm",
        "init_args": {
          "semantic_types": [
            "transform_algorithm"
          ],
          "values": [
            "lasso_lars",
            "lasso_cd",
            "lars",
            "omp",
            "threshold"
          ],
          "_structural_type": "str",
          "default": "omp",
          "description": "Algorithm used to transform the data:  - `'lars'`: uses the least angle regression method   (`linear_model.lars_path`); - `'lasso_lars'`: uses Lars to compute the Lasso solution. - `'lasso_cd'`: uses the coordinate descent method to compute the   Lasso solution (`linear_model.Lasso`). `'lasso_lars'` will be faster   if the estimated components are sparse. - `'omp'`: uses orthogonal matching pursuit to estimate the sparse   solution. - `'threshold'`: squashes to zero all coefficients less than alpha from   the projection ``dictionary * X'``."
        }
      },
      {
        "name": "transform_n_nonzero_coefs",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "transform_n_nonzero_coefs"
          ],
          "default": "transform_n_nonzero_coefs__None",
          "description": "Number of nonzero coefficients to target in each column of the solution. This is only used by `algorithm='lars'` and `algorithm='omp'` and is overridden by `alpha` in the `omp` case. If `None`, then `transform_n_nonzero_coefs=int(n_features / 10)`."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "transform_n_nonzero_coefs__int",
            "init_args": {
              "semantic_types": [
                "transform_n_nonzero_coefs"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "transform_n_nonzero_coefs__None",
            "init_args": {
              "semantic_types": [
                "transform_n_nonzero_coefs"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "name": "transform_alpha",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "transform_alpha"
          ],
          "default": "transform_alpha__None",
          "description": "If `algorithm='lasso_lars'` or `algorithm='lasso_cd'`, `alpha` is the penalty applied to the L1 norm. If `algorithm='threshold'`, `alpha` is the absolute value of the threshold below which coefficients will be squashed to zero. If `algorithm='omp'`, `alpha` is the tolerance parameter: the value of the reconstruction error targeted. In this case, it overrides `n_nonzero_coefs`. If `None`, default to 1."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "transform_alpha__float",
            "init_args": {
              "semantic_types": [
                "transform_alpha"
              ],
              "_structural_type": "float"
            }
          },
          {
            "type": "Constant",
            "name": "transform_alpha__None",
            "init_args": {
              "semantic_types": [
                "transform_alpha"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "type": "Hyperparameter",
        "name": "verbose",
        "init_args": {
          "semantic_types": [
            "verbose"
          ],
          "_structural_type": "bool",
          "default": "False",
          "description": "To control the verbosity of the procedure."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "split_sign",
        "init_args": {
          "semantic_types": [
            "split_sign"
          ],
          "_structural_type": "bool",
          "default": "False",
          "description": "Whether to split the sparse feature vector into the concatenation of its negative part and its positive part. This can improve the performance of downstream classifiers."
        }
      },
      {
        "name": "random_state",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "random_state"
          ],
          "default": "random_state__None",
          "description": "Used for initializing the dictionary when ``dict_init`` is not specified, randomly shuffling the data when ``shuffle`` is set to ``True``, and updating the dictionary. Pass an int for reproducible results across multiple function calls. See :term:`Glossary <random_state>`."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "random_state__int",
            "init_args": {
              "semantic_types": [
                "random_state"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "random_state__None",
            "init_args": {
              "semantic_types": [
                "random_state"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "type": "Hyperparameter",
        "name": "positive_code",
        "init_args": {
          "semantic_types": [
            "positive_code"
          ],
          "_structural_type": "bool",
          "default": "False",
          "description": "Whether to enforce positivity when finding the code.  .. versionadded:: 0.20"
        }
      },
      {
        "type": "Hyperparameter",
        "name": "positive_dict",
        "init_args": {
          "semantic_types": [
            "positive_dict"
          ],
          "_structural_type": "bool",
          "default": "False",
          "description": "Whether to enforce positivity when finding the dictionary.  .. versionadded:: 0.20"
        }
      },
      {
        "type": "Hyperparameter",
        "name": "transform_max_iter",
        "init_args": {
          "semantic_types": [
            "transform_max_iter"
          ],
          "_structural_type": "int",
          "default": 1000,
          "description": "Maximum number of iterations to perform if `algorithm='lasso_cd'` or `'lasso_lars'`.  .. versionadded:: 0.22"
        }
      }
    ],
    "Params": [
      {
        "name": "components_",
        "type": "ndarray of shape (n_components, n_features)",
        "description": "Components extracted from the data."
      },
      {
        "name": "inner_stats_",
        "type": "tuple of (A, B) ndarrays",
        "description": "Internal sufficient statistics that are kept by the algorithm. Keeping them is useful in online settings, to avoid losing the history of the evolution, but they shouldn't have any use for the end user. `A` `(n_components, n_components)` is the dictionary covariance matrix. `B` `(n_features, n_components)` is the data approximation matrix."
      },
      {
        "name": "n_iter_",
        "type": "int",
        "description": "Number of iterations run."
      },
      {
        "name": "iter_offset_",
        "type": "int",
        "description": "The number of iteration on data batches that has been performed before."
      },
      {
        "name": "random_state_",
        "type": "RandomState instance",
        "description": "RandomState instance that is generated either from a seed, the random number generattor or by `np.random`."
      }
    ]
  },
  "MiniBatchSparsePCA": {
    "name": "sklearn.decomposition._sparse_pca.MiniBatchSparsePCA",
    "common_name": "MiniBatchSparsePCA",
    "description": "Mini-batch Sparse Principal Components Analysis Finds the set of sparse components that can optimally reconstruct the data.  The amount of sparseness is controllable by the coefficient of the L1 penalty, given by the parameter alpha.  Read more in the :ref:`User Guide <SparsePCA>`.",
    "sklearn_version": "0.24.0",
    "Hyperparams": [
      {
        "name": "n_components",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "n_components"
          ],
          "default": "n_components__None",
          "description": "number of sparse atoms to extract"
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "n_components__int",
            "init_args": {
              "semantic_types": [
                "n_components"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "n_components__None",
            "init_args": {
              "semantic_types": [
                "n_components"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "type": "Hyperparameter",
        "name": "alpha",
        "init_args": {
          "semantic_types": [
            "alpha"
          ],
          "_structural_type": "int",
          "default": 1,
          "description": "Sparsity controlling parameter. Higher values lead to sparser components."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "ridge_alpha",
        "init_args": {
          "semantic_types": [
            "ridge_alpha"
          ],
          "_structural_type": "float",
          "default": 0.01,
          "description": "Amount of ridge shrinkage to apply in order to improve conditioning when calling the transform method."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "n_iter",
        "init_args": {
          "semantic_types": [
            "n_iter"
          ],
          "_structural_type": "int",
          "default": 100,
          "description": "number of iterations to perform for each mini batch"
        }
      },
      {
        "name": "callback",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "callback"
          ],
          "default": "callback__None",
          "description": "callable that gets invoked every five iterations"
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "callback__Callable",
            "init_args": {
              "semantic_types": [
                "callback"
              ],
              "_structural_type": "Callable"
            }
          },
          {
            "type": "Constant",
            "name": "callback__None",
            "init_args": {
              "semantic_types": [
                "callback"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "type": "Hyperparameter",
        "name": "batch_size",
        "init_args": {
          "semantic_types": [
            "batch_size"
          ],
          "_structural_type": "int",
          "default": 3,
          "description": "the number of features to take in each mini batch"
        }
      },
      {
        "name": "verbose",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "verbose"
          ],
          "default": "verbose__int",
          "description": "Controls the verbosity; the higher, the more messages. Defaults to 0."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "verbose__int",
            "init_args": {
              "semantic_types": [
                "verbose"
              ],
              "_structural_type": "int",
              "default": "False"
            }
          },
          {
            "type": "Hyperparameter",
            "name": "verbose__bool",
            "init_args": {
              "semantic_types": [
                "verbose"
              ],
              "_structural_type": "bool"
            }
          }
        ]
      },
      {
        "type": "Hyperparameter",
        "name": "shuffle",
        "init_args": {
          "semantic_types": [
            "shuffle"
          ],
          "_structural_type": "bool",
          "default": "True",
          "description": "whether to shuffle the data before splitting it in batches"
        }
      },
      {
        "name": "n_jobs",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "n_jobs"
          ],
          "default": "n_jobs__None",
          "description": "Number of parallel jobs to run. ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. ``-1`` means using all processors. See :term:`Glossary <n_jobs>` for more details."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "n_jobs__int",
            "init_args": {
              "semantic_types": [
                "n_jobs"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "n_jobs__None",
            "init_args": {
              "semantic_types": [
                "n_jobs"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "type": "Enumeration",
        "name": "method",
        "init_args": {
          "semantic_types": [
            "method"
          ],
          "values": [
            "lars",
            "cd"
          ],
          "_structural_type": "str",
          "default": "lars",
          "description": "lars: uses the least angle regression method to solve the lasso problem (linear_model.lars_path) cd: uses the coordinate descent method to compute the Lasso solution (linear_model.Lasso). Lars will be faster if the estimated components are sparse."
        }
      },
      {
        "name": "random_state",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "random_state"
          ],
          "default": "random_state__None",
          "description": "Used for random shuffling when ``shuffle`` is set to ``True``, during online dictionary learning. Pass an int for reproducible results across multiple function calls. See :term:`Glossary <random_state>`."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "random_state__int",
            "init_args": {
              "semantic_types": [
                "random_state"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "random_state__None",
            "init_args": {
              "semantic_types": [
                "random_state"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      }
    ],
    "Params": [
      {
        "name": "components_",
        "type": "ndarray of shape (n_components, n_features)",
        "description": "Sparse components extracted from the data."
      },
      {
        "name": "n_components_",
        "type": "int",
        "description": "Estimated number of components.  .. versionadded:: 0.23"
      },
      {
        "name": "n_iter_",
        "type": "int",
        "description": "Number of iterations run."
      },
      {
        "name": "mean_",
        "type": "ndarray of shape (n_features,)",
        "description": "Per-feature empirical mean, estimated from the training set. Equal to ``X.mean(axis=0)``."
      }
    ]
  },
  "NMF": {
    "name": "sklearn.decomposition._nmf.NMF",
    "common_name": "NMF",
    "description": "Non-Negative Matrix Factorization (NMF). Find two non-negative matrices (W, H) whose product approximates the non- negative matrix X. This factorization can be used for example for dimensionality reduction, source separation or topic extraction.  The objective function is:      .. math::          0.5 * ||X - WH||_{Fro}^2 + alpha * l1_{ratio} * ||vec(W)||_1          + alpha * l1_{ratio} * ||vec(H)||_1          + 0.5 * alpha * (1 - l1_{ratio}) * ||W||_{Fro}^2          + 0.5 * alpha * (1 - l1_{ratio}) * ||H||_{Fro}^2  Where:  :math:`||A||_{Fro}^2 = \\sum_{i,j} A_{ij}^2` (Frobenius norm)  :math:`||vec(A)||_1 = \\sum_{i,j} abs(A_{ij})` (Elementwise L1 norm)  For multiplicative-update ('mu') solver, the Frobenius norm (:math:`0.5 * ||X - WH||_{Fro}^2`) can be changed into another beta-divergence loss, by changing the beta_loss parameter.  The objective function is minimized with an alternating minimization of W and H.  Read more in the :ref:`User Guide <NMF>`.",
    "sklearn_version": "0.24.0",
    "Hyperparams": [
      {
        "name": "n_components",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "n_components"
          ],
          "default": "n_components__None",
          "description": "Number of components, if n_components is not set all features are kept."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "n_components__int",
            "init_args": {
              "semantic_types": [
                "n_components"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "n_components__None",
            "init_args": {
              "semantic_types": [
                "n_components"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "name": "init",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "init"
          ],
          "default": "init__str",
          "description": "Method used to initialize the procedure. Default: None. Valid options:  - None: 'nndsvd' if n_components <= min(n_samples, n_features),     otherwise random.  - 'random': non-negative random matrices, scaled with:     sqrt(X.mean() / n_components)  - 'nndsvd': Nonnegative Double Singular Value Decomposition (NNDSVD)     initialization (better for sparseness)  - 'nndsvda': NNDSVD with zeros filled with the average of X     (better when sparsity is not desired)  - 'nndsvdar': NNDSVD with zeros filled with small random values     (generally faster, less accurate alternative to NNDSVDa     for when sparsity is not desired)  - 'custom': use custom matrices W and H"
        },
        "hyperparams": [
          {
            "type": "Enumeration",
            "name": "init__str",
            "init_args": {
              "semantic_types": [
                "init"
              ],
              "values": [
                "random",
                "nndsvd",
                "nndsvda",
                "nndsvdar",
                "custom",
                "warn"
              ],
              "_structural_type": "str",
              "default": "warn"
            }
          },
          {
            "type": "Constant",
            "name": "init__None",
            "init_args": {
              "semantic_types": [
                "init"
              ],
              "_structural_type": "None"
            }
          }
        ]
      },
      {
        "type": "Enumeration",
        "name": "solver",
        "init_args": {
          "semantic_types": [
            "solver"
          ],
          "values": [
            "cd",
            "mu"
          ],
          "_structural_type": "str",
          "default": "cd",
          "description": "Numerical solver to use: 'cd' is a Coordinate Descent solver. 'mu' is a Multiplicative Update solver.  .. versionadded:: 0.17    Coordinate Descent solver.  .. versionadded:: 0.19    Multiplicative Update solver."
        }
      },
      {
        "name": "beta_loss",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "beta_loss"
          ],
          "default": "beta_loss__str",
          "description": "Beta divergence to be minimized, measuring the distance between X and the dot product WH. Note that values different from 'frobenius' (or 2) and 'kullback-leibler' (or 1) lead to significantly slower fits. Note that for beta_loss <= 0 (or 'itakura-saito'), the input matrix X cannot contain zeros. Used only in 'mu' solver.  .. versionadded:: 0.19"
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "beta_loss__float",
            "init_args": {
              "semantic_types": [
                "beta_loss"
              ],
              "_structural_type": "float"
            }
          },
          {
            "type": "Enumeration",
            "name": "beta_loss__str",
            "init_args": {
              "semantic_types": [
                "beta_loss"
              ],
              "values": [
                "frobenius",
                "kullback-leibler",
                "itakura-saito"
              ],
              "_structural_type": "str",
              "default": "frobenius"
            }
          }
        ]
      },
      {
        "type": "Hyperparameter",
        "name": "tol",
        "init_args": {
          "semantic_types": [
            "tol"
          ],
          "_structural_type": "float",
          "default": 0.0001,
          "description": "Tolerance of the stopping condition."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "max_iter",
        "init_args": {
          "semantic_types": [
            "max_iter"
          ],
          "_structural_type": "int",
          "default": 200,
          "description": "Maximum number of iterations before timing out."
        }
      },
      {
        "name": "random_state",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "random_state"
          ],
          "default": "random_state__None",
          "description": "Used for initialisation (when ``init`` == 'nndsvdar' or 'random'), and in Coordinate Descent. Pass an int for reproducible results across multiple function calls. See :term:`Glossary <random_state>`."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "random_state__int",
            "init_args": {
              "semantic_types": [
                "random_state"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "random_state__None",
            "init_args": {
              "semantic_types": [
                "random_state"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "type": "Hyperparameter",
        "name": "alpha",
        "init_args": {
          "semantic_types": [
            "alpha"
          ],
          "_structural_type": "float",
          "default": 0.0,
          "description": "Constant that multiplies the regularization terms. Set it to zero to have no regularization.  .. versionadded:: 0.17    *alpha* used in the Coordinate Descent solver."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "l1_ratio",
        "init_args": {
          "semantic_types": [
            "l1_ratio"
          ],
          "_structural_type": "float",
          "default": 0.0,
          "description": "The regularization mixing parameter, with 0 <= l1_ratio <= 1. For l1_ratio = 0 the penalty is an elementwise L2 penalty (aka Frobenius Norm). For l1_ratio = 1 it is an elementwise L1 penalty. For 0 < l1_ratio < 1, the penalty is a combination of L1 and L2.  .. versionadded:: 0.17    Regularization parameter *l1_ratio* used in the Coordinate Descent    solver."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "verbose",
        "init_args": {
          "semantic_types": [
            "verbose"
          ],
          "_structural_type": "int",
          "default": 0,
          "description": "Whether to be verbose."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "shuffle",
        "init_args": {
          "semantic_types": [
            "shuffle"
          ],
          "_structural_type": "bool",
          "default": "False",
          "description": "If true, randomize the order of coordinates in the CD solver.  .. versionadded:: 0.17    *shuffle* parameter used in the Coordinate Descent solver."
        }
      },
      {
        "type": "Enumeration",
        "name": "regularization",
        "init_args": {
          "semantic_types": [
            "regularization"
          ],
          "values": [
            "both",
            "components",
            "transformation",
            null
          ],
          "_structural_type": "str",
          "default": "both",
          "description": "Select whether the regularization affects the components (H), the transformation (W), both or none of them.  .. versionadded:: 0.24"
        }
      }
    ],
    "Params": [
      {
        "name": "components_",
        "type": "ndarray of shape (n_components, n_features)",
        "description": "Factorization matrix, sometimes called 'dictionary'."
      },
      {
        "name": "n_components_",
        "type": "int",
        "description": "The number of components. It is same as the `n_components` parameter if it was given. Otherwise, it will be same as the number of features."
      },
      {
        "name": "reconstruction_err_",
        "type": "float",
        "description": "Frobenius norm of the matrix difference, or beta-divergence, between the training data ``X`` and the reconstructed data ``WH`` from the fitted model."
      },
      {
        "name": "n_iter_",
        "type": "int",
        "description": "Actual number of iterations."
      }
    ]
  },
  "PCA": {
    "name": "sklearn.decomposition._pca.PCA",
    "common_name": "PCA",
    "description": "Principal component analysis (PCA). Linear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space. The input data is centered but not scaled for each feature before applying the SVD.  It uses the LAPACK implementation of the full SVD or a randomized truncated SVD by the method of Halko et al. 2009, depending on the shape of the input data and the number of components to extract.  It can also use the scipy.sparse.linalg ARPACK implementation of the truncated SVD.  Notice that this class does not support sparse input. See :class:`TruncatedSVD` for an alternative with sparse data.  Read more in the :ref:`User Guide <PCA>`.",
    "sklearn_version": "0.24.0",
    "Hyperparams": [
      {
        "name": "n_components",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "n_components"
          ],
          "default": "n_components__None",
          "description": "Number of components to keep. if n_components is not set all components are kept::      n_components == min(n_samples, n_features)  If ``n_components == 'mle'`` and ``svd_solver == 'full'``, Minka's MLE is used to guess the dimension. Use of ``n_components == 'mle'`` will interpret ``svd_solver == 'auto'`` as ``svd_solver == 'full'``.  If ``0 < n_components < 1`` and ``svd_solver == 'full'``, select the number of components such that the amount of variance that needs to be explained is greater than the percentage specified by n_components.  If ``svd_solver == 'arpack'``, the number of components must be strictly less than the minimum of n_features and n_samples.  Hence, the None case results in::      n_components == min(n_samples, n_features) - 1"
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "n_components__int",
            "init_args": {
              "semantic_types": [
                "n_components"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Hyperparameter",
            "name": "n_components__float",
            "init_args": {
              "semantic_types": [
                "n_components"
              ],
              "_structural_type": "float"
            }
          },
          {
            "type": "Constant",
            "name": "n_components__None",
            "init_args": {
              "semantic_types": [
                "n_components"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          },
          {
            "type": "Constant",
            "name": "n_components__str",
            "init_args": {
              "semantic_types": [
                "n_components"
              ],
              "_structural_type": "str"
            }
          }
        ]
      },
      {
        "type": "Hyperparameter",
        "name": "copy",
        "init_args": {
          "semantic_types": [
            "copy"
          ],
          "_structural_type": "bool",
          "default": "True",
          "description": "If False, data passed to fit are overwritten and running fit(X).transform(X) will not yield the expected results, use fit_transform(X) instead."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "whiten",
        "init_args": {
          "semantic_types": [
            "whiten"
          ],
          "_structural_type": "bool",
          "default": "False",
          "description": "When True (False by default) the `components_` vectors are multiplied by the square root of n_samples and then divided by the singular values to ensure uncorrelated outputs with unit component-wise variances.  Whitening will remove some information from the transformed signal (the relative variance scales of the components) but can sometime improve the predictive accuracy of the downstream estimators by making their data respect some hard-wired assumptions."
        }
      },
      {
        "type": "Enumeration",
        "name": "svd_solver",
        "init_args": {
          "semantic_types": [
            "svd_solver"
          ],
          "values": [
            "auto",
            "full",
            "arpack",
            "randomized"
          ],
          "_structural_type": "str",
          "default": "auto",
          "description": "If auto :     The solver is selected by a default policy based on `X.shape` and     `n_components`: if the input data is larger than 500x500 and the     number of components to extract is lower than 80% of the smallest     dimension of the data, then the more efficient 'randomized'     method is enabled. Otherwise the exact full SVD is computed and     optionally truncated afterwards. If full :     run exact full SVD calling the standard LAPACK solver via     `scipy.linalg.svd` and select the components by postprocessing If arpack :     run SVD truncated to n_components calling ARPACK solver via     `scipy.sparse.linalg.svds`. It requires strictly     0 < n_components < min(X.shape) If randomized :     run randomized SVD by the method of Halko et al.  .. versionadded:: 0.18.0"
        }
      },
      {
        "type": "Hyperparameter",
        "name": "tol",
        "init_args": {
          "semantic_types": [
            "tol"
          ],
          "_structural_type": "float",
          "default": 0.0,
          "description": "Tolerance for singular values computed by svd_solver == 'arpack'. Must be of range [0.0, infinity).  .. versionadded:: 0.18.0"
        }
      },
      {
        "name": "iterated_power",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "iterated_power"
          ],
          "default": "iterated_power__str",
          "description": "Number of iterations for the power method computed by svd_solver == 'randomized'. Must be of range [0, infinity).  .. versionadded:: 0.18.0"
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "iterated_power__int",
            "init_args": {
              "semantic_types": [
                "iterated_power"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "iterated_power__str",
            "init_args": {
              "semantic_types": [
                "iterated_power"
              ],
              "_structural_type": "str",
              "default": "auto"
            }
          }
        ]
      },
      {
        "name": "random_state",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "random_state"
          ],
          "default": "random_state__None",
          "description": "Used when the 'arpack' or 'randomized' solvers are used. Pass an int for reproducible results across multiple function calls. See :term:`Glossary <random_state>`.  .. versionadded:: 0.18.0"
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "random_state__int",
            "init_args": {
              "semantic_types": [
                "random_state"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "random_state__None",
            "init_args": {
              "semantic_types": [
                "random_state"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      }
    ],
    "Params": [
      {
        "name": "components_",
        "type": "ndarray of shape (n_components, n_features)",
        "description": "Principal axes in feature space, representing the directions of maximum variance in the data. The components are sorted by ``explained_variance_``."
      },
      {
        "name": "explained_variance_",
        "type": "ndarray of shape (n_components,)",
        "description": "The amount of variance explained by each of the selected components.  Equal to n_components largest eigenvalues of the covariance matrix of X.  .. versionadded:: 0.18"
      },
      {
        "name": "explained_variance_ratio_",
        "type": "ndarray of shape (n_components,)",
        "description": "Percentage of variance explained by each of the selected components.  If ``n_components`` is not set then all components are stored and the sum of the ratios is equal to 1.0."
      },
      {
        "name": "singular_values_",
        "type": "ndarray of shape (n_components,)",
        "description": "The singular values corresponding to each of the selected components. The singular values are equal to the 2-norms of the ``n_components`` variables in the lower-dimensional space.  .. versionadded:: 0.19"
      },
      {
        "name": "mean_",
        "type": "ndarray of shape (n_features,)",
        "description": "Per-feature empirical mean, estimated from the training set.  Equal to `X.mean(axis=0)`."
      },
      {
        "name": "n_components_",
        "type": "int",
        "description": "The estimated number of components. When n_components is set to 'mle' or a number between 0 and 1 (with svd_solver == 'full') this number is estimated from input data. Otherwise it equals the parameter n_components, or the lesser value of n_features and n_samples if n_components is None."
      },
      {
        "name": "n_features_",
        "type": "int",
        "description": "Number of features in the training data."
      },
      {
        "name": "n_samples_",
        "type": "int",
        "description": "Number of samples in the training data."
      },
      {
        "name": "noise_variance_",
        "type": "float",
        "description": "The estimated noise covariance following the Probabilistic PCA model from Tipping and Bishop 1999. See \"Pattern Recognition and Machine Learning\" by C. Bishop, 12.2.1 p. 574 or http://www.miketipping.com/papers/met-mppca.pdf. It is required to compute the estimated data covariance and score samples.  Equal to the average of (min(n_features, n_samples) - n_components) smallest eigenvalues of the covariance matrix of X."
      }
    ]
  },
  "SparseCoder": {
    "name": "sklearn.decomposition._dict_learning.SparseCoder",
    "common_name": "SparseCoder",
    "description": "Sparse coding Finds a sparse representation of data against a fixed, precomputed dictionary.  Each row of the result is the solution to a sparse coding problem. The goal is to find a sparse array `code` such that::      X ~= code * dictionary  Read more in the :ref:`User Guide <SparseCoder>`.",
    "sklearn_version": "0.24.0",
    "Hyperparams": [
      {
        "type": "Enumeration",
        "name": "transform_algorithm",
        "init_args": {
          "semantic_types": [
            "transform_algorithm"
          ],
          "values": [
            "lasso_lars",
            "lasso_cd",
            "lars",
            "omp",
            "threshold"
          ],
          "_structural_type": "str",
          "default": "omp",
          "description": "Algorithm used to transform the data:  - `'lars'`: uses the least angle regression method   (`linear_model.lars_path`); - `'lasso_lars'`: uses Lars to compute the Lasso solution; - `'lasso_cd'`: uses the coordinate descent method to compute the   Lasso solution (linear_model.Lasso). `'lasso_lars'` will be faster if   the estimated components are sparse; - `'omp'`: uses orthogonal matching pursuit to estimate the sparse   solution; - `'threshold'`: squashes to zero all coefficients less than alpha from   the projection ``dictionary * X'``."
        }
      },
      {
        "name": "transform_n_nonzero_coefs",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "transform_n_nonzero_coefs"
          ],
          "default": "transform_n_nonzero_coefs__None",
          "description": "Number of nonzero coefficients to target in each column of the solution. This is only used by `algorithm='lars'` and `algorithm='omp'` and is overridden by `alpha` in the `omp` case. If `None`, then `transform_n_nonzero_coefs=int(n_features / 10)`."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "transform_n_nonzero_coefs__int",
            "init_args": {
              "semantic_types": [
                "transform_n_nonzero_coefs"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "transform_n_nonzero_coefs__None",
            "init_args": {
              "semantic_types": [
                "transform_n_nonzero_coefs"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "name": "transform_alpha",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "transform_alpha"
          ],
          "default": "transform_alpha__None",
          "description": "If `algorithm='lasso_lars'` or `algorithm='lasso_cd'`, `alpha` is the penalty applied to the L1 norm. If `algorithm='threshold'`, `alpha` is the absolute value of the threshold below which coefficients will be squashed to zero. If `algorithm='omp'`, `alpha` is the tolerance parameter: the value of the reconstruction error targeted. In this case, it overrides `n_nonzero_coefs`. If `None`, default to 1."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "transform_alpha__float",
            "init_args": {
              "semantic_types": [
                "transform_alpha"
              ],
              "_structural_type": "float"
            }
          },
          {
            "type": "Constant",
            "name": "transform_alpha__None",
            "init_args": {
              "semantic_types": [
                "transform_alpha"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "type": "Hyperparameter",
        "name": "split_sign",
        "init_args": {
          "semantic_types": [
            "split_sign"
          ],
          "_structural_type": "bool",
          "default": "False",
          "description": "Whether to split the sparse feature vector into the concatenation of its negative part and its positive part. This can improve the performance of downstream classifiers."
        }
      },
      {
        "name": "n_jobs",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "n_jobs"
          ],
          "default": "n_jobs__None",
          "description": "Number of parallel jobs to run. ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. ``-1`` means using all processors. See :term:`Glossary <n_jobs>` for more details."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "n_jobs__int",
            "init_args": {
              "semantic_types": [
                "n_jobs"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "n_jobs__None",
            "init_args": {
              "semantic_types": [
                "n_jobs"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "type": "Hyperparameter",
        "name": "positive_code",
        "init_args": {
          "semantic_types": [
            "positive_code"
          ],
          "_structural_type": "bool",
          "default": "False",
          "description": "Whether to enforce positivity when finding the code.  .. versionadded:: 0.20"
        }
      },
      {
        "type": "Hyperparameter",
        "name": "transform_max_iter",
        "init_args": {
          "semantic_types": [
            "transform_max_iter"
          ],
          "_structural_type": "int",
          "default": 1000,
          "description": "Maximum number of iterations to perform if `algorithm='lasso_cd'` or `lasso_lars`.  .. versionadded:: 0.22"
        }
      }
    ],
    "Params": [
      {
        "name": "components_",
        "type": "ndarray of shape (n_components, n_features)",
        "description": "The unchanged dictionary atoms.  .. deprecated:: 0.24    This attribute is deprecated in 0.24 and will be removed in    1.1 (renaming of 0.26). Use `dictionary` instead."
      }
    ]
  },
  "SparsePCA": {
    "name": "sklearn.decomposition._sparse_pca.SparsePCA",
    "common_name": "SparsePCA",
    "description": "Sparse Principal Components Analysis (SparsePCA). Finds the set of sparse components that can optimally reconstruct the data.  The amount of sparseness is controllable by the coefficient of the L1 penalty, given by the parameter alpha.  Read more in the :ref:`User Guide <SparsePCA>`.",
    "sklearn_version": "0.24.0",
    "Hyperparams": [
      {
        "name": "n_components",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "n_components"
          ],
          "default": "n_components__None",
          "description": "Number of sparse atoms to extract."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "n_components__int",
            "init_args": {
              "semantic_types": [
                "n_components"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "n_components__None",
            "init_args": {
              "semantic_types": [
                "n_components"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "type": "Hyperparameter",
        "name": "alpha",
        "init_args": {
          "semantic_types": [
            "alpha"
          ],
          "_structural_type": "float",
          "default": 1,
          "description": "Sparsity controlling parameter. Higher values lead to sparser components."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "ridge_alpha",
        "init_args": {
          "semantic_types": [
            "ridge_alpha"
          ],
          "_structural_type": "float",
          "default": 0.01,
          "description": "Amount of ridge shrinkage to apply in order to improve conditioning when calling the transform method."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "max_iter",
        "init_args": {
          "semantic_types": [
            "max_iter"
          ],
          "_structural_type": "int",
          "default": 1000,
          "description": "Maximum number of iterations to perform."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "tol",
        "init_args": {
          "semantic_types": [
            "tol"
          ],
          "_structural_type": "float",
          "default": 1e-08,
          "description": "Tolerance for the stopping condition."
        }
      },
      {
        "type": "Enumeration",
        "name": "method",
        "init_args": {
          "semantic_types": [
            "method"
          ],
          "values": [
            "lars",
            "cd"
          ],
          "_structural_type": "str",
          "default": "lars",
          "description": "lars: uses the least angle regression method to solve the lasso problem (linear_model.lars_path) cd: uses the coordinate descent method to compute the Lasso solution (linear_model.Lasso). Lars will be faster if the estimated components are sparse."
        }
      },
      {
        "name": "n_jobs",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "n_jobs"
          ],
          "default": "n_jobs__None",
          "description": "Number of parallel jobs to run. ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. ``-1`` means using all processors. See :term:`Glossary <n_jobs>` for more details."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "n_jobs__int",
            "init_args": {
              "semantic_types": [
                "n_jobs"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "n_jobs__None",
            "init_args": {
              "semantic_types": [
                "n_jobs"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "name": "U_init",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "U_init"
          ],
          "default": "U_init__None",
          "description": "Initial values for the loadings for warm restart scenarios."
        },
        "hyperparams": [
          {
            "name": "U_init__ndarray",
            "type": "Hyperparameter",
            "init_args": {
              "_structural_type": "ndarray",
              "semantic_types": [
                "U_init"
              ]
            }
          },
          {
            "type": "Constant",
            "name": "U_init__None",
            "init_args": {
              "semantic_types": [
                "U_init"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "name": "V_init",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "V_init"
          ],
          "default": "V_init__None",
          "description": "Initial values for the components for warm restart scenarios."
        },
        "hyperparams": [
          {
            "name": "V_init__ndarray",
            "type": "Hyperparameter",
            "init_args": {
              "_structural_type": "ndarray",
              "semantic_types": [
                "V_init"
              ]
            }
          },
          {
            "type": "Constant",
            "name": "V_init__None",
            "init_args": {
              "semantic_types": [
                "V_init"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "name": "verbose",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "verbose"
          ],
          "default": "verbose__int",
          "description": "Controls the verbosity; the higher, the more messages. Defaults to 0."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "verbose__int",
            "init_args": {
              "semantic_types": [
                "verbose"
              ],
              "_structural_type": "int",
              "default": "False"
            }
          },
          {
            "type": "Hyperparameter",
            "name": "verbose__bool",
            "init_args": {
              "semantic_types": [
                "verbose"
              ],
              "_structural_type": "bool"
            }
          }
        ]
      },
      {
        "name": "random_state",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "random_state"
          ],
          "default": "random_state__None",
          "description": "Used during dictionary learning. Pass an int for reproducible results across multiple function calls. See :term:`Glossary <random_state>`."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "random_state__int",
            "init_args": {
              "semantic_types": [
                "random_state"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "random_state__None",
            "init_args": {
              "semantic_types": [
                "random_state"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      }
    ],
    "Params": [
      {
        "name": "components_",
        "type": "ndarray of shape (n_components, n_features)",
        "description": "Sparse components extracted from the data."
      },
      {
        "name": "error_",
        "type": "ndarray",
        "description": "Vector of errors at each iteration."
      },
      {
        "name": "n_components_",
        "type": "int",
        "description": "Estimated number of components.  .. versionadded:: 0.23"
      },
      {
        "name": "n_iter_",
        "type": "int",
        "description": "Number of iterations run."
      },
      {
        "name": "mean_",
        "type": "ndarray of shape (n_features,)",
        "description": "Per-feature empirical mean, estimated from the training set. Equal to ``X.mean(axis=0)``."
      }
    ]
  },
  "TruncatedSVD": {
    "name": "sklearn.decomposition._truncated_svd.TruncatedSVD",
    "common_name": "TruncatedSVD",
    "description": "Dimensionality reduction using truncated SVD (aka LSA). This transformer performs linear dimensionality reduction by means of truncated singular value decomposition (SVD). Contrary to PCA, this estimator does not center the data before computing the singular value decomposition. This means it can work with sparse matrices efficiently.  In particular, truncated SVD works on term count/tf-idf matrices as returned by the vectorizers in :mod:`sklearn.feature_extraction.text`. In that context, it is known as latent semantic analysis (LSA).  This estimator supports two algorithms: a fast randomized SVD solver, and a \"naive\" algorithm that uses ARPACK as an eigensolver on `X * X.T` or `X.T * X`, whichever is more efficient.  Read more in the :ref:`User Guide <LSA>`.",
    "sklearn_version": "0.24.0",
    "Hyperparams": [
      {
        "type": "Hyperparameter",
        "name": "n_components",
        "init_args": {
          "semantic_types": [
            "n_components"
          ],
          "_structural_type": "int",
          "default": 2,
          "description": "Desired dimensionality of output data. Must be strictly less than the number of features. The default value is useful for visualisation. For LSA, a value of 100 is recommended."
        }
      },
      {
        "type": "Enumeration",
        "name": "algorithm",
        "init_args": {
          "semantic_types": [
            "algorithm"
          ],
          "values": [
            "arpack",
            "randomized"
          ],
          "_structural_type": "str",
          "default": "randomized",
          "description": "SVD solver to use. Either \"arpack\" for the ARPACK wrapper in SciPy (scipy.sparse.linalg.svds), or \"randomized\" for the randomized algorithm due to Halko (2009)."
        }
      },
      {
        "type": "Hyperparameter",
        "name": "n_iter",
        "init_args": {
          "semantic_types": [
            "n_iter"
          ],
          "_structural_type": "int",
          "default": 5,
          "description": "Number of iterations for randomized SVD solver. Not used by ARPACK. The default is larger than the default in :func:`~sklearn.utils.extmath.randomized_svd` to handle sparse matrices that may have large slowly decaying spectrum."
        }
      },
      {
        "name": "random_state",
        "type": "Union",
        "init_args": {
          "semantic_types": [
            "random_state"
          ],
          "default": "random_state__None",
          "description": "Used during randomized svd. Pass an int for reproducible results across multiple function calls. See :term:`Glossary <random_state>`."
        },
        "hyperparams": [
          {
            "type": "Hyperparameter",
            "name": "random_state__int",
            "init_args": {
              "semantic_types": [
                "random_state"
              ],
              "_structural_type": "int"
            }
          },
          {
            "type": "Constant",
            "name": "random_state__None",
            "init_args": {
              "semantic_types": [
                "random_state"
              ],
              "_structural_type": "None",
              "default": "None"
            }
          }
        ]
      },
      {
        "type": "Hyperparameter",
        "name": "tol",
        "init_args": {
          "semantic_types": [
            "tol"
          ],
          "_structural_type": "float",
          "default": 0.0,
          "description": "Tolerance for ARPACK. 0 means machine precision. Ignored by randomized SVD solver."
        }
      }
    ],
    "Params": [
      {
        "name": "components_",
        "type": "ndarray of shape (n_components, n_features)",
        "description": ""
      },
      {
        "name": "explained_variance_",
        "type": "ndarray of shape (n_components,)",
        "description": "The variance of the training samples transformed by a projection to each component."
      },
      {
        "name": "explained_variance_ratio_",
        "type": "ndarray of shape (n_components,)",
        "description": "Percentage of variance explained by each of the selected components."
      },
      {
        "name": "singular_values_",
        "type": "ndarray od shape (n_components,)",
        "description": "The singular values corresponding to each of the selected components. The singular values are equal to the 2-norms of the ``n_components`` variables in the lower-dimensional space."
      }
    ]
  }
}